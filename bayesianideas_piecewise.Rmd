---
title: "BIDA in Stan: Piecewise constant hazard Cox"
author: "Kazuki Yoshida"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r bayesianideas_piecewise-1, message = FALSE, tidy = FALSE, echo = F}
## knitr configuration: http://yihui.name/knitr/options#chunk_options
library(knitr)
showMessage <- FALSE
showWarning <- TRUE
set_alias(w = "fig.width", h = "fig.height", res = "results")
opts_chunk$set(comment = "##", error= TRUE, warning = showWarning, message = showMessage,
               tidy = FALSE, cache = F, echo = T,
               fig.width = 7, fig.height = 7, dev.args = list(family = "sans"))
## for rgl
## knit_hooks$set(rgl = hook_rgl, webgl = hook_webgl)
## for animation
opts_knit$set(animation.fun = hook_ffmpeg_html)

## R configuration
options(width = 116, scipen = 5)

## Record start time
start_time <- Sys.time()
## cat("### Started ", as.character(start_time), "\n")

## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend for foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
## Report multicore use
## cat("### Using", foreach::getDoParWorkers(), "cores\n")
## cat("### Using", foreach::getDoParName(), "as backend\n")
```

## References
- Online
  - [Stan Leukemia example](https://github.com/stan-dev/example-models/blob/master/bugs_examples/vol1/leuk/leuk.stan)
  - [Stan for survival models](https://discourse.mc-stan.org/t/stan-for-survival-models/4146)
  - [PyMC3 Bayesian Survival Analysis](https://docs.pymc.io/notebooks/survival_analysis.html)
  - [Piece-Wise Exponential Model](http://data.princeton.edu/wws509/notes/c7s4.html)
  - [Stan-dev Prior Choice Recommendations](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)
- Books
  - [(BIDA) Bayesian Ideas and Data Analysis An Introduction for Scientists and Statisticians](http://blogs.oregonstate.edu/bida/)
  - [(BUGS) The BUGS Book: A Practical Introduction to Bayesian Analysis](https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-the-bugs-book/)
  - [(BSA) Bayesian Survival Analysis](https://www.springer.com/us/book/9780387952772)


## Background

The proportional hazards (PH) model (Cox 1972) is a very popular regression method for survival data. The popularity likely originated in not having to specify the (baseline) hazard function. These days, it is popular probably because it is the only survival regression model that many applied researchers are aware of. In Frequentist PH model, parameter estimation is conducted via partial likelihood from which the baseline hazard function has dropped out (BSA p16).

In Bayesian paradigm, obtaining the posterior distribution of parameters requires the full likelihood function involving all parameters including nuisance ones and the prior for all these parameters. In the case of survival analysis, one of the parameters that requires modeling is the entire baseline hazard function. One way to proceed is to parametrize the baseline hazard function parsimoniously, i.e., parametric survival analysis (BIDA p325, BSA chap 2). The other approach is to more flexibly model the baseline hazard function.

Here we will examine the simplest form of the latter, the piecewise constant hazard model (piecewise exponential model).

## Piecewise constant hazard model
### Likelihood

This model formulation was taken from BSA (p47-).

Firstly, partition the time axis into $J$ intervals using $0 < s_{1} < s_{2} ... < s_{J} < \infty$.

 $$(0,s_{1}], (s_{1},s_{2}], ..., (s_{J-1},s_{J}]$$

$s_{J}$ is a finite value that has to be larger than the largest observed time in the study. Name each interval $I_{j} = (s_{j-1},s_{j}]$. We assume a constant hazard $\lambda$ within each interval. Let $D = (n,\mathbf{y}, X, \nu)$ describe the observed data.

$\mathbf{y} = (y_{1}, ..., y_{n})^{T}$ is the observed times.

$X$ is a $n \times p$ matrix of covariates associated with a length $p$ vector $\boldsymbol{\beta}$.

$\boldsymbol{\nu} = (\nu_{1},...,\nu_{n})^{T}$ is a vector of failure (censoring) indicators.

Let $\boldsymbol{\lambda} = (\lambda_{1},...,\lambda_{J})^{T}$. The full likelihood for $(\boldsymbol{\beta}, \boldsymbol{\lambda})$ is the following.

$$L(\boldsymbol{\beta},\boldsymbol{\lambda} | D) = \prod^{n}_{i=1} \prod^{J}_{j=1} (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{ij}\nu_{i}} \exp \left\{ - \delta_{ij} \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$$

where $\delta_{ij}$ is an interval specific indicator of end of follow up indicator $I[y_{i} \in I_{j}]$.

This is really hard, so let us dissect this into more manageable pieces. Firstly, we will focus on one individual rather than the entire dataset.

$$L(\boldsymbol{\beta},\boldsymbol{\lambda} | D_{i}) = \prod^{J}_{j=1} (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{ij}\nu_{i}} \exp \left\{ - \delta_{ij} \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$$

Thus, this is a product of interval-specific contributions. However, for interval $I_{j}$ in which the individual just survived without death or censoring $\delta_{ij} = 0$, there is no contribution (no parameters left).

$$(\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{(0) \nu_{i}} \exp \left\{ - (0) \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\} = 1$$

Therefore, the only contribution happens at the interval when the individual either dies or becomes censored. Note in general, an event individual contributes a density, which is a product of hazard and survival. On the other hand, a censored individual can only contribute survival information.


### Event individual contribution

Firstly, we will consider death in interval $I_{j}$.

$$(\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{(1) (1)} \exp \left\{ - (1) \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$$

$(\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{(1) (1)}$ is the hazard contribution.

$\exp \left\{ - (1) \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$ is the survival contribution. Taken together this individual contributes density information.

Note $\left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right]$ is the cumulative baseline hazard that this individual faced. By multiplying this with time-constant (by the PH assumption) multiplication factor, $\exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta})$, we obtain the individual-specific cumulative hazard. An exponential of the negative cumulative hazard is the survival.

### Censored individual contribution

Now we will consider censoring in interval $I_{j}$.

$$(\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{(1) (0)} \exp \left\{ - (1) \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$$

$(\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{(1) (0)} = 1$. There is no hazard contribution.

$\exp \left\{ - (1) \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}$ is the survival contribution.

### Poisson trick

This part follows BIDA (p347-) and [Piece-Wise Exponential Model](http://data.princeton.edu/wws509/notes/c7s4.html). Let us examine the likelihood for individual $i$ further. As stated above only contribution happens at the interval in which follow up ends by death or censoring. Without loss of generality, consider this interval as $I_{j}$.

$$
\begin{align*}
L(\boldsymbol{\beta},\boldsymbol{\lambda} | D_{i})
&= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{ij}\nu_{i}} \exp \left\{ - \delta_{ij} \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &~~~\text{By } \delta_{ij} = 1\\
 &= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \exp \left\{ - \left[ \lambda_{j}(y_{i} - s_{j-1}) + \sum^{j-1}_{g=1} \lambda_{g}(s_{g} - s_{g-1}) \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &~~~\text{Let $H_{i,g}$ represent at-risk time during $I_{g}$ for $i$}.\\
 &= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \exp \left\{ - \left[ \sum^{j}_{g=1} \lambda_{g} H_{i,g} \right] \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \exp \left\{ - \sum^{j}_{g=1} \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &~~~\text{Note the new middle piece is 1.}\\
 &= (\lambda_{j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \left[ \prod^{j-1}_{g=1} (\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{0} \right] \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &\propto (\lambda_{j} H_{i,j} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\nu_{i}} \left[ \prod^{j-1}_{g=1} (\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{0} \right] \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &~~~\text{By reintroducing } \delta_{i,g} \text{, which is 0 for }g < j\\
 &= \left[ \prod^{j}_{g=1} (\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{i,g} \nu_{i}} \right] \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\}\\
 &= \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\} (\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{i,g} \nu_{i}}\\
 &~~~\text{By } \delta_{i,g} \nu_{i} \in \{0,1\}\\
 &= \prod^{j}_{g=1} \exp \left\{ - \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}) \right\} (\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))^{\delta_{i,g} \nu_{i}} \big/ (\delta_{i,g} \nu_{i})!\\
\end{align*}
$$

We can multiply the likelihood with a term that does not contain parameters and retain the same inference. Note the last expression is a product of individual- and interval-specific Poisson likelihood. This transformation implies that we can split each individual's observation into interval-specific observations up until the interval in which follow up ended. In addition to copying covariates, each interval-specific observation has to have the duration of the at-risk time and an indicator that is 1 in the last interval if the individual died otherwise 0. The latter indicator serves as the outcome of the Poisson model.

The corresponding Poisson model for individual $i$ interval $g$ is the following.

$$
\begin{align*}
\mu_{i,g} &= \lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta})\\
\log(\mu_{i,g}) &= \log(\lambda_{g} H_{i,g} \exp(\mathbf{x}_{i}^{T}\boldsymbol{\beta}))\\
 &= \log(H_{i,g}) + \log(\lambda_{g}) + \mathbf{x}_{i}^{T}\boldsymbol{\beta}\\
 &= \log(H_{i,g}) + \beta_{0,g} + \mathbf{x}_{i}^{T}\boldsymbol{\beta}\\
\end{align*}
$$

Therefore, $\log(H_{i,g})$ becomes the offset. The intercept $\beta_{0,g} = \log(\lambda_{g})$ is interval-specific. The outcome, the indicator variable $(\delta_{i,g} \nu_{i})$ is not independent within an individual because it is all zero except the last one, which can be 1 if the individual died. However, the likelihood has the form of a product of interval-specific Poisson contributions. Thus, the Poisson modeling can proceed as if these interval-specific observations from one individual were independent. In R, [survival::survSplit](https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survSplit.html) function can create this long-format dataset from a single-row-per-person dataset.


### Prior specification

We have clarified the likelihood part, so now we need to specify the priors for all parameters. We have the covariate coefficient vector $\boldsymbol{\beta}$. After the Poisson transformation, we also have the interval-specific intercepts. Each one of the parameters can take on any value on the real line.

The Stan developer website has a web page dedicated to prior choice philosophy [(Prior Choice Recommendations)](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations). Here we adopt the principle of weakly informative priors that are informative enough to regularize. The direct quote is the following.


> Weakly informative prior should contain enough information to regularize: the idea is that the prior rules out unreasonable parameter values but is not so strong as to rule out values that might make sense.

#### Priors for covariate coefficients

These coefficients for covariates are on the log hazard ratio scale. Based on the substantive ground, we would like to rule out hazard ratios that are greater than 50 or smaller than 1/50. $\log(50) = 3.912023$. Thus, $N(0,2^2)$ may be a good choice. This prior puts approximately 5% of the prior probability located outside the above stated reasonable range.

#### Priors for baseline hazards

BSA (p48) suggests independent gamma priors for the piecewise baseline hazard parameters and multivariate normal prior for the vector of log baseline hazard parameters. BSA does not mention numerical values. It is hard to think of the reasonable range for the piecewise baseline hazards.

BUGS (p290) uses independent $Gamma(0.001, 0.001)$ (```dgamma```) as a prior for each $\lambda$. This has mean 1 and variance 1000.

BIDA (p351-) acknowledges this difficulty and suggest centering the priors on an exponential regression model.

$$\lambda_{k} \sim Gamma(\lambda_{*}w_{k}, w_{k})$$

where $w_{k}$ is the interval length times some hyperparameter $w$.


## Data analysis example
### Set up multicore environment

```{r bayesianideas_piecewise-2 }
## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend with foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
## Report multicore use
## cat("### Using", foreach::getDoParWorkers(), "cores\n")
## cat("### Using", foreach::getDoParName(), "as backend\n")
```

### Load packages

```{r bayesianideas_piecewise-3 }
library(tidyverse)
library(survival)
library(rstanarm)
library(broom)
library(directlabels)
```

### Load and prepare dataset

```
aml                  package:survival                  R Documentation
Acute Myelogenous Leukemia survival data
Description:
     Survival in patients with Acute Myelogenous Leukemia.  The
     question at the time was whether the standard course of
     chemotherapy should be extended ('maintainance') for additional
     cycles.
Usage:
     aml
     leukemia
Format:
       time:    survival or censoring time
       status:  censoring status
       x:       maintenance chemotherapy given? (factor)
Source:
     Rupert G. Miller (1997), _Survival Analysis_.  John Wiley & Sons.
     ISBN: 0-471-25218-2.
```

```{r bayesianideas_piecewise-4 }
data(leukemia, package = "survival")
leukemia <- as_tibble(leukemia) %>%
    mutate(id = seq_len(n())) %>%
    select(id, everything())
leukemia
```

Check distribution of observed times and decide cut points for piecewise constant hazard function.

```{r bayesianideas_piecewise-5 }
## One piece
cut_one <- max(leukemia$time) + 1
cut_one
## Two pieces
cut_two <- c(median(leukemia$time), cut_one) %>% round()
cut_two
## Three pieces
cut_three <- c(quantile(leukemia$time, probs = c(1/3, 2/3)), cut_one) %>% round()
cut_three
## At all event times
cut_events <- c(leukemia %>%
                filter(status == 1) %>%
                select(time) %>%
                arrange(time) %>%
                magrittr::extract2("time") %>%
                unique,
                cut_one) %>% round()
cut_events
## At all event or censoring
cut_times <- c(sort(unique(leukemia$time)),
               cut_one) %>% round()
cut_times
```

Now transform dataset into long-format ones. We need an interval indicator and an interval length variable.

```{r bayesianideas_piecewise-6 }
## No cut for all same constant hazard
leukemia_one <- survival::survSplit(formula = Surv(time, status) ~ ., data = leukemia, cut = cut_one) %>%
    mutate(interval = factor(tstart),
           interval_length = time - tstart) %>%
    as_data_frame
leukemia_one
## Split into two observations
leukemia_two <- survival::survSplit(formula = Surv(time, status) ~ ., data = leukemia, cut = cut_two) %>%
    mutate(interval = factor(tstart),
           interval_length = time - tstart) %>%
    as_data_frame
leukemia_two
## Split into three observations
leukemia_three <- survival::survSplit(formula = Surv(time, status) ~ ., data = leukemia, cut = cut_three) %>%
    mutate(interval = factor(tstart),
           interval_length = time - tstart) %>%
    as_data_frame
leukemia_three
## Split at event times
leukemia_events <- survival::survSplit(formula = Surv(time, status) ~ ., data = leukemia, cut = cut_events) %>%
    mutate(interval = factor(tstart),
           interval_length = time - tstart) %>%
    as_data_frame
leukemia_events
## Split at event and censoring times
leukemia_times <- survival::survSplit(formula = Surv(time, status) ~ ., data = leukemia, cut = cut_times) %>%
    mutate(interval = factor(tstart),
           interval_length = time - tstart) %>%
    as_data_frame
leukemia_times
```

### Sanity check with frequentist methods

```{r bayesianideas_piecewise-7 }
coxph(formula = Surv(time, status) ~ x,
         data    = leukemia,
         ties    = c("efron","breslow","exact")[1]) %>% summary
glm(formula = status ~ x + offset(log(interval_length)),
    family  = poisson(link = "log"),
    data    = leukemia_one) %>% summary
## Drop intercept to show all interval-specific log rates
glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
    data = leukemia_two,
    family = poisson(link = "log")) %>% summary
glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
    data = leukemia_three,
    family = poisson(link = "log")) %>% summary
glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
    data = leukemia_events,
    family = poisson(link = "log")) %>% summary
glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
    data = leukemia_times,
    family = poisson(link = "log")) %>% summary
```

Some log baseline hazard estimates are -22.8454 with a standard error of 8693.5021. This non-convergence of the MLE algorithm occurs if the interval (a,b] does not contain any event, such as (13,16] in the model that defined intervals by all observed times. There is only one censoring at time 16 in this interval.

### Model with rstanarm

Here we will use normal priors because they are readily available in rstanarm. Centering the prior for a log hazard ratio parameter at 0 (hazard ratio 1) sounds reasonable.

Where to center the prior for a log baseline hazard is unclear, so we will center it around 0, but make it vague. Here we will use $N(0,4^2)$, which means 95% of the prior probability is in [-7.839856, +7.839856] on the natural log scale.

We will remove the intercept term to make all interval terms parametrized as log baseline hazard (rather than change from the initial log baseline hazard). rstanarm does not seem to allow a different prior for each regression coefficient. So we will just use $N(0,4^2)$ for all.

```{r bayesianideas_piecewise-8 }
fit_leukemia_one <- rstanarm::stan_glm(formula = status ~ x + offset(log(interval_length)),
                                       data = leukemia_one,
                                       family = poisson(link = "log"),
                                       prior_intercept = normal(location = 0, scale = 4),
                                       prior = normal(location = 0, scale = 4))
prior_summary(fit_leukemia_one)
summary(fit_leukemia_one)

fit_leukemia_two <- rstanarm::stan_glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
                                       data = leukemia_two,
                                       family = poisson(link = "log"),
                                       prior = normal(location = 0, scale = 4))
prior_summary(fit_leukemia_two)
summary(fit_leukemia_two)

fit_leukemia_three <- rstanarm::stan_glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
                                         data = leukemia_three,
                                         family = poisson(link = "log"),
                                         prior = normal(location = 0, scale = 4))
prior_summary(fit_leukemia_three)
summary(fit_leukemia_three)

fit_leukemia_events <- rstanarm::stan_glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
                                          data = leukemia_events,
                                          family = poisson(link = "log"),
                                          prior = normal(location = 0, scale = 4))
prior_summary(fit_leukemia_events)
summary(fit_leukemia_events)

fit_leukemia_times <- rstanarm::stan_glm(formula = status ~ -1 + interval + x + offset(log(interval_length)),
                                         data = leukemia_times,
                                         family = poisson(link = "log"),
                                         prior = normal(location = 0, scale = 4))
prior_summary(fit_leukemia_times)
summary(fit_leukemia_times)
```

By the virtue of regularization by the prior, even the log baseline hazards for intervals without events does not break the model, but has lower posterior means.

Examine model fit with loo. Note @avehtari ([tweet](https://twitter.com/avehtari/status/1063048345118273536), BDA3 co-author, developer of Stan, GPy, etc!) pointed out that in the case of sub-patient level dataset (multiple rows representing intervals for each patient), leave-one-observation-out method is tricky. In this instance, what each observation represents in terms of the duration of the interval is different across models. This likely requires manually coded cross-validation with patient-level nested data frame (each row represents one patient with multiple time points nested within it). The evaluation was suppressed as the results are misleading.

```{r bayesianideas_piecewise-9, eval = FALSE}
list_fits_leukemia <- list(fit_leukemia_one = fit_leukemia_one,
                           fit_leukemia_two = fit_leukemia_two,
                           fit_leukemia_three = fit_leukemia_three,
                           fit_leukemia_events = fit_leukemia_events,
                           fit_leukemia_times = fit_leukemia_times)
lapply(list_fits_leukemia, loo::loo)
```


### Survival curve prediction

Now we have posterior samples of interval-specific log baseline hazards as well as log hazard ratio for treatment. We can construct treatment group-specific posterior survival curves. Since we have piecewise constant hazards, it is easier to first construct a cumulative hazard function. Here is the constructor.

```{r bayesianideas_piecewise-10 }
cunstruct_cumulative_hazard_function <- function(cutpoints, log_baseline_hazards, group_effect) {

    ## t is a vector of time points. group is {0,1} scalar
    cumulative_hazard_function <- function(t, group) {
        ## Boolean for any exposed time in each interval
        ## length(cutpoints) x length(t)
        interval_exposed <- outer(cutpoints, t, `<`)

        ## t - cutpoint. Multiply by interval exposed to avoid negative times.
        time_exposed <-  -outer(cutpoints, t, `-`) * interval_exposed

        ## Last interval is of width Inf
        interval_widths <- c(diff(cutpoints), Inf)

        ## For each interval, time exposed cannot exceed interval width.
        time_exposed_correct  <- sweep(x = time_exposed,
                                       MARGIN = 1,
                                       STATS = interval_widths,
                                       FUN = pmin)

        ## Multiply by corresponding baseline hazards to get interval specific cumulative baseline hazards.
        interval_baseline_cumulative_hazards <- sweep(x = time_exposed_correct,
                                                      MARGIN = 1,
                                                      STATS = exp(log_baseline_hazards),
                                                      FUN = `*`)

        ## Cumulative baseline hazard vector length(t)
        baseline_cumulative_hazards <- colSums(interval_baseline_cumulative_hazards)

        ## return after applying group effect
        return(baseline_cumulative_hazards * exp(group_effect * group))
    }

    return(cumulative_hazard_function)
}
```

We can use the tidybayes package to obtain each posterior sample as a row of a data frame. The columns named interval are interval-specific constant log hazards.

```{r bayesianideas_piecewise-11 }
tidybayes::tidy_draws(fit_leukemia_three)
```

Then we construct posterior samples of cumulative hazard functions based on the interval-specific constant log hazards. No-so-tidy tidyverse code follows.

```{r bayesianideas_piecewise-12 }
cum_haz_leukemia_one <- tidybayes::tidy_draws(fit_leukemia_one) %>%
    mutate(`H(t|x)` = pmap(list(`(Intercept)`, xNonmaintained),
                           function(`(Intercept)`, xNonmaintained){
                               cunstruct_cumulative_hazard_function(
                                   cutpoints = c(0),
                                   log_baseline_hazards = c(`(Intercept)`),
                                   group_effect = xNonmaintained)
                           })) %>%
    select(.chain, .iteration, .draw, `H(t|x)`)

cum_haz_leukemia_two <- tidybayes::tidy_draws(fit_leukemia_two) %>%
    mutate(`H(t|x)` = pmap(list(interval0, interval23, xNonmaintained),
                           function(interval0, interval23, xNonmaintained){
                               cunstruct_cumulative_hazard_function(
                                   cutpoints = c(0,23),
                                   log_baseline_hazards = c(interval0, interval23),
                                   group_effect = xNonmaintained)
                           })) %>%
    select(.chain, .iteration, .draw, `H(t|x)`)

cum_haz_leukemia_three <- tidybayes::tidy_draws(fit_leukemia_three) %>%
    mutate(`H(t|x)` = pmap(list(interval0, interval14, interval31, xNonmaintained),
                           function(interval0, interval14, interval31, xNonmaintained){
                               cunstruct_cumulative_hazard_function(
                                   cutpoints = c(0,14,31),
                                   log_baseline_hazards = c(interval0, interval14, interval31),
                                   group_effect = xNonmaintained)
                           })) %>%
    select(.chain, .iteration, .draw, `H(t|x)`)

cum_haz_leukemia_events <- tidybayes::tidy_draws(fit_leukemia_events) %>%
    mutate(`H(t|x)` = pmap(list(interval0, interval5, interval8, interval9, interval12,
                                interval13, interval18, interval23, interval27, interval30,
                                interval31, interval33, interval34, interval43, interval45,
                                interval48, xNonmaintained),
                           function(interval0, interval5, interval8, interval9, interval12,
                                    interval13, interval18, interval23, interval27, interval30,
                                    interval31, interval33, interval34, interval43, interval45,
                                    interval48, xNonmaintained){
                               cunstruct_cumulative_hazard_function(
                                   cutpoints = c(0, 5, 8, 9, 12, 13, 18, 23, 27, 30, 31, 33, 34, 43, 45, 48),
                                   log_baseline_hazards = c(interval0, interval5, interval8, interval9,
                                                            interval12, interval13, interval18, interval23,
                                                            interval27, interval30, interval31, interval33,
                                                            interval34, interval43, interval45, interval48),
                                   group_effect = xNonmaintained)
                           })) %>%
    select(.chain, .iteration, .draw, `H(t|x)`)



cum_haz_leukemia_times <- tidybayes::tidy_draws(fit_leukemia_times) %>%
    mutate(`H(t|x)` = pmap(list(interval0, interval5, interval8, interval9, interval12, interval13,
                                interval16, interval18, interval23, interval27, interval28, interval30,
                                interval31, interval33, interval34, interval43, interval45, interval48,
                                xNonmaintained),
                           function(interval0, interval5, interval8, interval9, interval12, interval13,
                                    interval16, interval18, interval23, interval27, interval28, interval30,
                                    interval31, interval33, interval34, interval43, interval45, interval48,
                                    xNonmaintained){
                               cunstruct_cumulative_hazard_function(
                                   cutpoints = c(0, 5, 8, 9, 12, 13, 16, 18, 23, 27, 28, 30, 31, 33,
                                                 34, 43, 45, 48),
                                   log_baseline_hazards = c(interval0, interval5, interval8, interval9,
                                                            interval12, interval13, interval16, interval18,
                                                            interval23, interval27, interval28, interval30,
                                                            interval31, interval33, interval34, interval43,
                                                            interval45, interval48),
                                   group_effect = xNonmaintained)
                           })) %>%
    select(.chain, .iteration, .draw, `H(t|x)`)
```

As you can see, each row corresponds to a posterior sample of a cumulative hazard function that can be evaluated at an arbitrary time point $t \ge 0$.

```{r bayesianideas_piecewise-13 }
cum_haz_leukemia_times
```

Here we define functions to create plotting data and to plot.

```{r bayesianideas_piecewise-14 }
create_plot_df <- function(cum_haz_leukemia_df) {
    ## Evaluation time points
    times_df <- data_frame(t = seq(from = 0, to = cut_one, by = 1))

    cum_haz_leukemia_df %>%
        mutate(times_df = list(times_df)) %>%
        mutate(times_df = pmap(list(times_df, `H(t|x)`),
                               function(times_df, `H(t|x)`) {
                                   times_df %>%
                                       mutate(`H(t|1)` = `H(t|x)`(t, 1),
                                              `H(t|0)` = `H(t|x)`(t, 0)) %>%
                                       mutate(`S(t|1)` = exp(-`H(t|1)`),
                                              `S(t|0)` = exp(-`H(t|0)`)) %>%
                                       select(-`H(t|1)`, -`H(t|0)`)
                               }
                               )
               ) %>%
        select(-`H(t|x)`) %>%
        unnest() %>%
        gather(key = treatment,
               value = survival,
               `S(t|1)`, `S(t|0)`) %>%
        mutate(treatment = factor(treatment,
                                  levels = c("S(t|0)", "S(t|1)"),
                                  labels = c("Maintained","Nonmaintained")))
}

summarize_df <- function(df) {
    df %>%
        group_by(treatment, t) %>%
        summarize(survival_mean = mean(survival),
                  survival_95upper = quantile(survival, probs = 0.975),
                  survival_95lower = quantile(survival, probs = 0.025))
}

plot_df <- function(df) {
    df_summary <- summarize_df(df)

    df %>%
        ggplot(mapping = aes(x = t, y = survival,
                             group = interaction(.chain, .iteration, .draw, treatment))) +
        geom_line(size = 0.1, alpha = 0.025) +
        geom_line(data = df_summary,
                  mapping = aes(y = survival_mean, group = treatment)) +
        geom_line(data = df_summary,
                  mapping = aes(y = survival_95upper, group = treatment),
                  linetype = "dotted") +
        geom_line(data = df_summary,
                  mapping = aes(y = survival_95lower, group = treatment),
                  linetype = "dotted") +
        facet_grid(. ~ treatment) +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
              legend.key = element_blank(),
              plot.title = element_text(hjust = 0.5),
              strip.background = element_blank())
}
```

Plot different models.

```{r bayesianideas_piecewise-15 }
survival_leukemia_one <-
    cum_haz_leukemia_one %>%
    create_plot_df()
survival_leukemia_one %>%
    plot_df() +
    labs(title = "One constant hazard")
```

```{r bayesianideas_piecewise-16 }
survival_leukemia_two <-
    cum_haz_leukemia_two %>%
    create_plot_df()
survival_leukemia_two %>%
    plot_df() +
    labs(title = "Two constant hazards")
```

```{r bayesianideas_piecewise-17 }
survival_leukemia_three <-
    cum_haz_leukemia_three %>%
    create_plot_df()
survival_leukemia_three %>%
    plot_df() +
    labs(title = "Three constant hazards")
```

```{r bayesianideas_piecewise-18 }
survival_leukemia_events <-
    cum_haz_leukemia_events %>%
    create_plot_df()
survival_leukemia_events %>%
    plot_df() +
    labs(title = "All event times")
```

```{r bayesianideas_piecewise-19 }
survival_leukemia_times <-
    cum_haz_leukemia_times %>%
    create_plot_df()
survival_leukemia_times %>%
    plot_df() +
    labs(title = "All times")
```

```{r bayesianideas_piecewise-20 }
## Frequentist Kaplan-Meier estimates
km_leukemia_fit <- survival::survfit(formula = Surv(time, status) ~ x,
                                     data = leukemia,
                                     type      = "kaplan-meier",
                                     error     = "greenwood",
                                     conf.type = "log-log")
survival_leukemia_km <-
    km_leukemia_fit %>%
    broom::tidy() %>%
    mutate(treatment = gsub("x=", "", strata),
           model = "Kaplan-Meier") %>%
    rename(t = time,
           ## These are misnomers, but for plotting purpuse.
           survival_mean = estimate,
           survival_95upper = conf.high,
           survival_95lower = conf.low) %>%
    select(treatment, t, survival_mean, survival_95upper, survival_95lower, model) %>%
    right_join(y = crossing(treatment = c("Maintained","Nonmaintained"),
                            t = seq(from = 0, to = cut_one, by = 1),
                            model = "Kaplan-Meier")) %>%
    mutate(treatment = factor(treatment,
                              levels = c("Maintained","Nonmaintained"))) %>%
    arrange(treatment, t) %>%
    mutate(survival_mean = if_else(t == 0, 1, survival_mean),
           survival_95upper = if_else(t == 0, 1, survival_95upper),
           survival_95lower = if_else(t == 0, 1, survival_95lower)) %>%
    ## Need LOCF to recover step function
    tidyr::fill(survival_mean, survival_95upper, survival_95lower,
                .direction = "down")
```

Now plot together for comparison. Note the Kaplan-Meier estimates are Frequentist estimates. The Kaplan-Meier interval is Frequentist 95% confidence interval. For other methods, the intervals are 95% credible intervals (posterior probability intervals).

```{r bayesianideas_piecewise-21 }
## Summarize
survival_leukemia_together <-
    bind_rows(
        survival_leukemia_one %>%
        summarize_df() %>%
        mutate(model = "One constant hazard"),
        survival_leukemia_two %>%
        summarize_df() %>%
        mutate(model = "Two constant hazards"),
        survival_leukemia_three %>%
        summarize_df() %>%
        mutate(model = "Three constant hazards"),
        survival_leukemia_events %>%
        summarize_df() %>%
        mutate(model = "All event times"),
        survival_leukemia_times %>%
        summarize_df() %>%
        mutate(model = "All times"),
        ## KM
        survival_leukemia_km)

gg_together <- survival_leukemia_together %>%
    ggplot(mapping = aes(x = t, y = survival_mean,
                         group = interaction(treatment, model), color = model)) +
    geom_line() +
    geom_line(mapping = aes(y = survival_95upper),
              linetype = "dotted") +
    geom_line(mapping = aes(y = survival_95lower),
              linetype = "dotted") +
    facet_grid(. ~ treatment) +
    labs(x = "Time in Days", y = "Survival") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
## Regular plot
gg_together
## Direct labeling
directlabels::direct.label(gg_together + scale_x_continuous(limit = c(0, 200)))
```

All methods are similar for the Nonmaintained group, whereas there are larger differences for the Maintained group. This is likely due to departure from the exponential model (One constant hazard).


## Record session information

```{r bayesianideas_piecewise-22 }
print(sessionInfo())
## Record execution time
end_time <- Sys.time()
cat("Started  ", as.character(start_time), "\n")
cat("Finished ", as.character(end_time), "\n")
print(end_time - start_time)
```
--------------------
- Top Page: http://rpubs.com/kaz_yos/
- Github: https://github.com/kaz-yos
