---
title: "Bayesian Causal Inference"
author: "Kazuki Yoshida"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r, message = FALSE, tidy = FALSE, echo = F}
## knitr configuration: http://yihui.name/knitr/options#chunk_options
library(knitr)
showMessage <- FALSE
showWarning <- TRUE
set_alias(w = "fig.width", h = "fig.height", res = "results")
opts_chunk$set(comment = "##", error= TRUE, warning = showWarning, message = showMessage,
               tidy = FALSE, cache = FALSE, echo = TRUE,
               fig.width = 7, fig.height = 7, dev.args = list(family = "sans"))
## for rgl
## knit_hooks$set(rgl = hook_rgl, webgl = hook_webgl)
## for animation
opts_knit$set(animation.fun = hook_ffmpeg_html)
## R configuration
options(width = 116, scipen = 5)
## Record start time
start_time <- Sys.time()
## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend for foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
```

## References
- [Stan (+R) Workshop 2019 at Calvin College](https://rpruim.github.io/StanWorkshop/)
- [An easy way to simulate fake data from your Stan model](http://modernstatisticalworkflow.blogspot.com/2017/04/an-easy-way-to-simulate-fake-data-from.html?m=1)
- [A Bayesian approach to the g-formula](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5790647/)
- [Posterior Predictive Treatment Assignment for Estimating Causal Effects with Limited Overlap](https://arxiv.org/abs/1710.08749)

## Load packages
Here we use the ```distributed``` that I wrote for a previous simulation project ([Comparison of Privacy-Protecting Analytic and Data-sharing Methods: a Simulation Study](https://github.com/kaz-yos/distributed)).
```{r}
## random.org
set.seed(272438315)
library(tidyverse)
## Simulation suite from
## https://github.com/kaz-yos/distributed
## devtools::install_github(repo = "kaz-yos/distributed")
library(distributed)
library(rstan)
library(bayesplot)
```

## Generate data
The following function can be used to construct a single dataset with treated and untreated with confounding.
```
     GenerateOneCenter(n, AssignCovariates, alphas, betas, survParams)

Arguments:

       n: study site-specific sample size

AssignCovariates: covariate generation functions that takes n and p as
          the only arguments.

  alphas: parameter vector for treatment model including c(alpha0,
          alphaX)

   betas: parameter vector for outcome model shared among binary and
          survival outcome models including ‘c(beta0, betaX, betaA,
          betaXA)’.

survParams: vector of two. The first element is the baseline hazard of
          events in the exponential event time outcome model
          (‘lambda’). The second element is the baseline hazard of
          censoring in the exponential censoring time model
          (‘lambda_c’).
```
This function call produces both binary and survival outcome. We focus on the binary outcome.
```{r}
data1 <-
    GenerateOneCenter(n = 1000,
                      AssignCovariates = AssignCovariatesNormBinDefault,
                      alphas = c(alpha0 = -0.5, alphaX = c(0.5, 0.5)),
                      betas = c(beta0 = -0.5, betaX = c(0.5, 0.5),
                                ## Protective effect
                                betaA = -0.3,
                                ## No effect (measure) modification
                                betaXA = c(0, 0)),
                      survParams = c(lambda = -log(0.95), lambda_c = -log(0.99), Tmax = 1))
```
The true data including the counterfactual quantities can be displayed. The overall difference in pY0 (mean probability of response under no treatment) and pY1 (mean probability of response under treatment) is the average treatment effect (ATE). The same thing in the treated (A=1) is the average treatment effect on the treated (ATT). The treatment group difference in pY0 indicates difference in the mean counterfactuals under no treatment. That is, confounding. Similar confounding exhibits in pY1.
```{r}
summary(data1, truth = TRUE)
```
The data structure is a regular data frame. To ease modeling with Stan, create a model matrix.
```{r}
## Each row is c(1, A, X1, X2)
AX <- model.matrix( ~ A + X1 + X2, data = data1)
head(AX)
## Each row is c(1, X1, X2)
X <- model.matrix( ~ X1 + X2, data = data1)
head(X)
## Outcome vector
y <- data1$Y
## Treatment vector
A <- data1$A
```
The true conditional effect is the coefficient betaA (log OR). The true marginal causal effects are the following.
```{r}
## ATE
as_tibble(data1) %>%
    summarize(`True RD` = mean(pY1) - mean(pY0),
              `True RR` = mean(pY1) / mean(pY0))
```

## Regular logistic regression
```{r}
logit_stan <- rstan::stan_model("./bayesian_causal1_logistic.stan")
logit_stan
```
### Prior only fit for prior predictive check
```{r, results = "hide"}
logit_stan_fit_prior <-
    rstan::sampling(logit_stan,
                    data = list(p = ncol(AX),
                                beta_mean = c(0, 0, 0, 0),
                                beta_sd = c(10, 5, 5, 5),
                                N = nrow(AX),
                                y = y,
                                X = AX,
                                use_lik = 0))
```
```{r}
## Check HMC diagnostics after sampling
rstan::check_hmc_diagnostics(logit_stan_fit_prior)
## Specify relevant parameters
pars <- c("beta","lp__")
## Print a summary for a fitted model represented by a 'stanfit' object
print(logit_stan_fit_prior, pars = pars)
## Create a matrix of output plots from a 'stanfit' object
pairs(logit_stan_fit_prior, pars = pars)
## Markov chain traceplots
rstan::traceplot(logit_stan_fit_prior, pars = pars, inc_warmup = FALSE)
## Trace plots of MCMC draws
regex_pars <- c("beta")
bayesplot::mcmc_rank_hist(logit_stan_fit_prior, regex_pars = regex_pars, ref_line = TRUE)
bayesplot::mcmc_rank_overlay(logit_stan_fit_prior, regex_pars = regex_pars, ref_line = TRUE)
```
Visualize the conditional treatment effect.
```{r}
bayesplot::mcmc_areas(as.matrix(logit_stan_fit_prior),
                      pars = c("beta[2]"),
                      prob = 0.9)
```
exp(10) = 22,026. So this prior may be too diffuse and does not regularize much. We can further check the prior predictive distribution.
```{r}
y_rep <- as.matrix(logit_stan_fit_prior, pars = c("y_rep"))
ppc_dens_overlay(y, y_rep[sample(seq_len(nrow(y_rep)), 200),])
ppc_stat(y = y, yrep = y_rep, stat = mean)
```
In this binary outcome setting, the density overlay approach is not very useful. We can use the mean (proportion of 1) as a summary to be compared. Here it should be reasonably broad such that all values are covered. ppc_stat shows the summary of the data, but this should be ignored here.

### Posterior fit
```{r, results = "hide"}
logit_stan_fit <-
    rstan::sampling(logit_stan,
                    data = list(p = ncol(AX),
                                beta_mean = c(0, 0, 0, 0),
                                beta_sd = c(10, 5, 5, 5),
                                N = nrow(AX),
                                y = y,
                                X = AX,
                                use_lik = 1))
```
```{r}
## Check HMC diagnostics after sampling
rstan::check_hmc_diagnostics(logit_stan_fit)
## Specify relevant parameters
pars <- c("beta","lp__")
## Print a summary for a fitted model represented by a 'stanfit' object
print(logit_stan_fit, pars = pars)
## Create a matrix of output plots from a 'stanfit' object
pairs(logit_stan_fit, pars = pars)
## Markov chain traceplots
rstan::traceplot(logit_stan_fit, pars = pars, inc_warmup = FALSE)
## Trace plots of MCMC draws
regex_pars <- c("beta")
bayesplot::mcmc_rank_hist(logit_stan_fit, regex_pars = regex_pars, ref_line = TRUE)
bayesplot::mcmc_rank_overlay(logit_stan_fit, regex_pars = regex_pars, ref_line = TRUE)
```
Visualize the conditional treatment effect.
```{r}
bayesplot::mcmc_areas(as.matrix(logit_stan_fit),
                      pars = c("beta[2]"),
                      prob = 0.9)
```
Now we can examine the posterior predictive distribution.
```{r}
y_rep <- as.matrix(logit_stan_fit, pars = c("y_rep"))
ppc_dens_overlay(y, y_rep[sample(seq_len(nrow(y_rep)), 200),])
ppc_stat(y = y, yrep = y_rep, stat = mean)
```
ppc_stat shows the summary of the data, which is nicely covered by the posterior predictive counterparts.


## Simple "g-formula"
Here we simply marginalize over the observed distribution of covariates as our treatment variable is time-fixed. When the treatment variable is time-varying, the treatment strategies (regimes) can involve specification of treatment values at multiple time points. This usually give rise to time-varying confounders that are affected by previous treatment. In this case, post-baseline covariates also need to be modeled. Here we are in a simpler setting.
```{r}
logit_gf_stan <- rstan::stan_model("./bayesian_causal1_logistic_gf.stan")
logit_gf_stan
```
To ease the posterior prediction process, here we create the counterfactual design matrices. The treatment variable and associated terms if any are manipulated.
```{r}
## Counterfactual treatment assignment
data1$A0 <- 0
data1$A1 <- 1
## For ATE estimation, use all data but with counterfactual assignments.
AX0_ate <- model.matrix( ~ A0 + X1 + X2, data = data1)
AX1_ate <- model.matrix( ~ A1 + X1 + X2, data = data1)
## For ATT estimation
AX0_att <- model.matrix( ~ A0 + X1 + X2, data = subset(data1, A == 1))
AX1_att <- model.matrix( ~ A1 + X1 + X2, data = subset(data1, A == 1))
```
### Prior predictive
```{r, results = "hide"}
logit_gf_stan_ate_fit_prior <-
    rstan::sampling(logit_gf_stan,
                    data = list(p = ncol(AX),
                                beta_mean = c(0, 0, 0, 0),
                                beta_sd = c(10, 5, 5, 5),
                                N = nrow(AX),
                                y = y,
                                X = AX,
                                N_new = nrow(AX0_ate),
                                X0 = AX0_ate,
                                X1 = AX1_ate,
                                use_lik = 0))
```
```{r}
## Check HMC diagnostics after sampling
rstan::check_hmc_diagnostics(logit_gf_stan_ate_fit_prior)
## Specify relevant parameters
pars <- c("beta","lp__")
## Print a summary for a fitted model represented by a 'stanfit' object
print(logit_gf_stan_ate_fit_prior, pars = pars)
## Create a matrix of output plots from a 'stanfit' object
pairs(logit_gf_stan_ate_fit_prior, pars = pars)
## Markov chain traceplots
rstan::traceplot(logit_gf_stan_ate_fit_prior, pars = pars, inc_warmup = FALSE)
## Trace plots of MCMC draws
regex_pars <- c("beta")
bayesplot::mcmc_rank_hist(logit_gf_stan_ate_fit_prior, regex_pars = regex_pars, ref_line = TRUE)
bayesplot::mcmc_rank_overlay(logit_gf_stan_ate_fit_prior, regex_pars = regex_pars, ref_line = TRUE)
```
Visualize the marginal treatment effect.
```{r}
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_ate_fit_prior),
                      pars = c("rd"),
                      prob = 0.9)
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_ate_fit_prior),
                      pars = c("rr"),
                      prob = 0.9)
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_ate_fit_prior),
                      pars = c("rr"),
                      prob = 0.9) +
    geom_vline(xintercept = 1, alpha = 0.1) +
    scale_x_continuous(limits = c(0, 25))
```
We do not directly specify priors on the marginal treatment effects. These are implied by the priors on the coefficients. So there may be a value in checking the implied priors. Interestingly, the implied prior on the risk difference is quite concentrated around zero difference although the range essentially covers all possible values. The implied prior on the risk ratio also concentrate at 1 (zero difference) although the range is very wide. Another peak near 0 is likely an artifact of the asymmetric scale (vs symmetric log RR scale).

### ATE estimation
We estimate the posterior for the ATE here.
```{r, results = "hide"}
logit_gf_stan_ate_fit <-
    rstan::sampling(logit_gf_stan,
                    data = list(p = ncol(AX),
                                beta_mean = c(0, 0, 0, 0),
                                beta_sd = c(10, 5, 5, 5),
                                N = nrow(AX),
                                y = y,
                                X = AX,
                                N_new = nrow(AX0_ate),
                                X0 = AX0_ate,
                                X1 = AX1_ate,
                                use_lik = 1))
```
We first check the soundness of the HMC diagnostics.
```{r}
## Check HMC diagnostics after sampling
rstan::check_hmc_diagnostics(logit_gf_stan_ate_fit)
## Specify relevant parameters
pars <- c("beta","lp__")
## Print a summary for a fitted model represented by a 'stanfit' object
print(logit_gf_stan_ate_fit, pars = pars)
## Create a matrix of output plots from a 'stanfit' object
pairs(logit_gf_stan_ate_fit, pars = pars)
## Markov chain traceplots
rstan::traceplot(logit_gf_stan_ate_fit, pars = pars, inc_warmup = FALSE)
## Trace plots of MCMC draws
regex_pars <- c("beta")
bayesplot::mcmc_rank_hist(logit_gf_stan_ate_fit, regex_pars = regex_pars, ref_line = TRUE)
bayesplot::mcmc_rank_overlay(logit_gf_stan_ate_fit, regex_pars = regex_pars, ref_line = TRUE)
```
The results we care are not the posterior for the coefficients, but the ATE.
```{r}
print(logit_gf_stan_ate_fit, pars = c("rd","rr"))
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_ate_fit),
                      pars = c("rd"),
                      prob = 0.9)
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_ate_fit),
                      pars = c("rr"),
                      prob = 0.9)
```
For more precise results, we can extract quantities.
```{r}
post_ate <- as.data.frame(logit_gf_stan_ate_fit, pars = c("rd","rr")) %>%
    as_tibble
post_ate %>%
    summarize(`P[RD < 0]` = mean(rd < 0),
              `P[RD < -0.05]` = mean(rd < -0.05),
              `P[RR < 1.0]` = mean(rr < 1.0),
              `P[RR < 0.9]` = mean(rr < 0.9)) %>%
    gather(key = Statement, value = `Posterior Prob.`)
```
The last row represents the posterior probability for the counterfactual risk ratio being less than 0.9 (greater than 10% risk reductrion by hypothetical intervention on everyone).

### ATT estimation
We estimate the posterior for the ATT here. We need to refit the model is we want to calculate the predictions for the manipulated design matrix for the treated individuals in Stan.
```{r, results = "hide"}
logit_gf_stan_att_fit <-
    rstan::sampling(logit_gf_stan,
                    data = list(p = ncol(AX),
                                beta_mean = c(0, 0, 0, 0),
                                beta_sd = c(10, 5, 5, 5),
                                N = nrow(AX),
                                y = y,
                                X = AX,
                                N_new = nrow(AX0_att),
                                X0 = AX0_att,
                                X1 = AX1_att,
                                use_lik = 1))
```
We first check the soundness of the HMC diagnostics.
```{r}
## Check HMC diagnostics after sampling
rstan::check_hmc_diagnostics(logit_gf_stan_att_fit)
## Specify relevant parameters
pars <- c("beta","lp__")
## Print a summary for a fitted model represented by a 'stanfit' object
print(logit_gf_stan_att_fit, pars = pars)
## Creatt a matrix of output plots from a 'stanfit' object
pairs(logit_gf_stan_att_fit, pars = pars)
## Markov chain traceplots
rstan::traceplot(logit_gf_stan_att_fit, pars = pars, inc_warmup = FALSE)
## Trace plots of MCMC draws
regex_pars <- c("beta")
bayesplot::mcmc_rank_hist(logit_gf_stan_att_fit, regex_pars = regex_pars, ref_line = TRUE)
bayesplot::mcmc_rank_overlay(logit_gf_stan_att_fit, regex_pars = regex_pars, ref_line = TRUE)
```
The results we care are not the posterior for the coefficients, but the ATT.
```{r}
print(logit_gf_stan_att_fit, pars = c("rd","rr"))
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_att_fit),
                      pars = c("rd"),
                      prob = 0.9)
bayesplot::mcmc_areas(as.matrix(logit_gf_stan_att_fit),
                      pars = c("rr"),
                      prob = 0.9)
```
For more precise results, we can extract quantities.
```{r}
post_att <- as.data.frame(logit_gf_stan_att_fit, pars = c("rd","rr")) %>%
    as_tibble
post_att %>%
    summarize(`P[RD < 0]` = mean(rd < 0),
              `P[RD < -0.05]` = mean(rd < -0.05),
              `P[RR < 1.0]` = mean(rr < 1.0),
              `P[RR < 0.9]` = mean(rr < 0.9)) %>%
    gather(key = Statement, value = `Posterior Prob.`)
```
The last row represents the posterior probability for the counterfactual risk ratio being less than 0.9 (greater than 10% risk reductrion by hypothetical intervention on treated vs "untreating them"). We did not introduce effect (measure) modification to the data generation mechanism or the design matrix, thus, the results should be similar to the ATE.


## Propensity score modeling
Bayesian approaches to propensity score (PS) are an evolving area of methodological research. Originally, joint simultaneous modeling of a PS model and outcome model was proposed. It was later realized this allowed feedback from the outcome model to the PS model, which is considered inconsistent with the notion of the separation of the design stage and analysis stage.

TO BE CONTINUED...

--------------------
- Top Page: http://rpubs.com/kaz_yos/
- Github: https://github.com/kaz-yos

```{r}
print(sessionInfo())
## Record execution time and multicore use
end_time <- Sys.time()
diff_time <- difftime(end_time, start_time, units = "auto")
cat("Started  ", as.character(start_time), "\n",
    "Finished ", as.character(end_time), "\n",
    "Time difference of ", diff_time, " ", attr(diff_time, "units"), "\n",
    "Used ", foreach::getDoParWorkers(), " cores\n",
    "Used ", foreach::getDoParName(), " as backend\n",
    sep = "")
```
