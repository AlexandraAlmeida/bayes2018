---
title: "BIDA: Density Estimation (Finite Mixture Model)"
author: "Kazuki Yoshida"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r, message = FALSE, tidy = FALSE, echo = F}
## knitr configuration: http://yihui.name/knitr/options#chunk_options
library(knitr)
showMessage <- FALSE
showWarning <- TRUE
set_alias(w = "fig.width", h = "fig.height", res = "results")
opts_chunk$set(comment = "##", error= TRUE, warning = showWarning, message = showMessage,
               tidy = FALSE, cache = FALSE, echo = TRUE,
               fig.width = 7, fig.height = 7, dev.args = list(family = "sans"))
## for rgl
## knit_hooks$set(rgl = hook_rgl, webgl = hook_webgl)
## for animation
opts_knit$set(animation.fun = hook_ffmpeg_html)
## R configuration
options(width = 116, scipen = 5)
## Record start time
start_time <- Sys.time()
## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend for foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
```

## References
- Books
  - [(BIDA) Bayesian Ideas and Data Analysis An Introduction for Scientists and Statisticians](http://blogs.oregonstate.edu/bida/)
  - [(BDA) Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)
- Web sites
  - [Bayesian Statistics Using Stan 10 Finite Mixtures](http://www.stat.columbia.edu/~gelman/bda.course/_book/mixture-modeling-chapter.html)
  - [Finite mixture models in Stan](http://modernstatisticalworkflow.blogspot.com/2016/10/finite-mixture-models-in-stan.html)
  - [Identifying Bayesian Mixture Models](http://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html)
  - [Taming Divergences in Stan Models](https://www.martinmodrak.cz/2018/02/19/taming-divergences-in-stan-models/)
  - [Check HMC diagnostics after sampling](http://mc-stan.org/rstan/reference/check_hmc_diagnostics.html)
  - [Mixture models in Stan: you can use log_mix](https://andrewgelman.com/2017/08/21/mixture-models-stan-can-use-log_mix/)
  - [Identification of mixture of multivariate normal distributions](https://discourse.mc-stan.org/t/identification-of-mixture-of-multivariate-normal-distributions/4203)
- jSoftware
  - [Stan Modeling Language User's Guide and Reference Manual, Version 2.17.0](http://mc-stan.org/users/documentation/)
  - [CRAN DPpackage: Bayesian Nonparametric Modeling in R](https://cran.r-project.org/package=DPpackage)
  - [J Stat Softw. 2011. DPpackage: Bayesian Non- and Semi-parametric Modelling in R.](https://www.jstatsoft.org/article/view/v040i05)


## Background
Here we have 82 data points in the galaxy from a 1-dimensional unknown distribution. The aim is to fit a normal finite mixture model with a pre-specified number of latent clusters.

## Assessment thus-far
Each chain seems to converge to something, but the mixing of several chains are very poor. Is there still a label switching issue although the means are ordered in the prior?


## Load packages

```{r}
library(tidyverse)
library(rstan)
## devtools::install_github('jburos/biostan', build_vignettes = TRUE, dependencies = TRUE)
## library(biostan)
library(DPpackage)
set.seed(732565397)
```

## Prepare data
```{r}
data(galaxy, package = "DPpackage")
galaxy <- galaxy %>%
    as_data_frame() %>%
    mutate(log_speed = log(speed),
           k_speed = speed / 1000)
galaxy
ggplot(data = galaxy, mapping = aes(x = k_speed)) +
    geom_point(y = 0.5) +
    scale_y_continuous(limits = c(0,1), breaks = NULL) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
```

The speed data seem to show some distinct clusters. We will use the following grid for later visualization.

```{r}
grid_max <- 40
grid_min <- -20
grid_length <- 100
```

## Single Normal
We will start with density estimation with a single normal distribution as a starting point.

### Model
$$\begin{align*}
  y_{i} | (\mu, \sigma^{2}) &\sim N(\mu, \sigma^{2})\\
  \\
  p(\mu,\sigma^{2}) &= p(\mu|\sigma^{2})p(\sigma^{2})\\
  &= N(\mu | m, s^{2}) Inverse-Gamma(\sigma^{2} | \alpha, \beta)\\
  &= \left[ \frac{1}{\sqrt{2\pi s^{2}}} \exp \left( - \frac{(\mu - m)^{2}}{2 \times s^{2}} \right) \right]
    \left[ \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^{2})^{-\alpha - 1} \exp \left( - \frac{\beta}{\sigma^{2}} \right) \right]\\
  &\text{where}\\
  m &= 0\\
  s^{2} &= 10^{3}\\
  \alpha &= 10^{-3}\\
  \beta &= 10^{-3}\\
  \end{align*}
$$

### Implementation
```{r}
normal_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal.stan")
biostan::print_stan_code(normal_stan_code, section = NULL)
```

### Fitting
Helper functions for here and later use.
```{r}
print_relevant_pars <- function(fit, pars = c("mu","sigma_squared","Pi","sigma","lp__")) {
    print(fit, pars = pars)
}

traceplot_all <- function(fit, pars = c("mu","sigma","Pi","lp__")) {
    for (par in pars) {
        print(traceplot(fit, inc_warmup = TRUE, pars = par))
    }
}

pairs_plot_all <- function(fit, pars = c("mu","sigma_squared","Pi")) {
    for (par in pars) {
        pairs(fit, pars = par)
    }
}

plot_draws <- function(stan_fit) {
    ## Note direct access to global variables
    draw_data  <- tidybayes::tidy_draws(stan_fit) %>%
        select(.chain, .iteration, .draw, starts_with("log_f")) %>%
        gather(key = key, value = value, starts_with("log_f")) %>%
        mutate(key = gsub("log_f|\\[|\\]", "", key) %>% as.integer(),
           x = factor(key, labels = seq(from = grid_min, to = grid_max, length.out = grid_length)) %>%
               as.character() %>%
               as.numeric(),
           value = exp(value))

    summary_density <- draw_data %>%
        group_by(.chain, x) %>%
        summarize(value = mean(value))

    ggplot(data = draw_data, mapping = aes(x = x, y = value,
           group = interaction(.chain, .iteration, .draw))) +
    ## geom_line(size = 0.1, alpha = 1/20) +
    geom_line(data = summary_density, mapping = aes(group = .chain), size = 0.5, color = "gray") +
    geom_point(data = galaxy, mapping = aes(x = k_speed, group = NULL), y = 0) +
    facet_wrap(~ .chain) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
}
```
```{r, results = 'hide'}
normal_stan_fit <-
    rstan::stan(model_code = normal_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```

```{r}
print(normal_stan_fit, pars = c("mu","sigma","lp__"))
```

The sampling process seems ok. Plot density function draws.

```{r}
plot_draws(normal_stan_fit)
```

Apparently, a single normal distribution model is not a sufficient description of the density.


## Finite Mixture of Normals

Now we examine if modeling the distribution as a mixture of several underlying cluster-specific normals better fit the data. Here we assume some fixed number of clusters $H$.

### Model
Let $z_{i} \in \left\{ 1, \dots, H \right\}$ be the cluster membership latent variable and $\mathbf{z}_{i} = (I(z_{i}=1),\dots,I(z_{i}=H))^{T}$ be the vector indicator version. We have the following model.

$$\begin{align*}
  y_{i} | (z_{i}, \mu_{1},\dots,\mu_{H}, \sigma^{2}_{1},\dots,\sigma^{2}_{H}) &\sim N(\mu_{z_{i}}, \sigma^{2}_{z_{i}})\\
  \mathbf{z}_{i} | \boldsymbol{\pi} &\sim Multinomial(1, \boldsymbol{\pi})\\
  \\
  p(\mu_{h},\sigma^{2}_{h}) &= p(\mu_{h}|\sigma^{2}_{h})p(\sigma^{2}_{h})\\
  &= N(\mu_{h} | m, s^{2}) Inverse-Gamma(\sigma^{2}_{h} | \alpha, \beta)\\
  &= \left[ \frac{1}{\sqrt{2\pi s^{2}}} \exp \left( - \frac{(\mu_{h} - m)^{2}}{2 \times s^{2}} \right) \right]
    \left[ \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^{2}_{h})^{-\alpha - 1} \exp \left( - \frac{\beta}{\sigma^{2}_{h}} \right) \right]\\
  &\text{where}\\
  m &= 0\\
  s^{2} &= 10^{3}\\
  \alpha &= 10^{-3}\\
  \beta &= 10^{-3}\\
  \\
  p(\boldsymbol{\pi}) &\sim Dirichlet \left( \frac{\alpha}{H}, \dots, \frac{\alpha}{H} \right)\\
  \end{align*}
$$

Summing out the latent categorical variable $z_{i}$ results in the following (conditioning on parameters suppressed for simplicity) marginal density. Note the cluster membership latent variable $z_i$ is not measured, thus, it is a discrete parameter. Stan's Hamiltonian Monte Carlo (HMC) cannot deal with discrete parameters, this marginalization step is required fro Stan. JAGS, which implements Gibbs sampling, allows a discrete parameter and accepts the original model above.

$$\begin{align*}
  p(y) &= \sum^{H}_{z=1} p(y|z) p(z)\\
  &= \sum^{H}_{z=1} \pi_{z} p(y|z)\\
  &= \sum^{H}_{h=1} \pi_h N(y | \mu_{h}, \sigma^{2}_{h})\\
  \end{align*}
$$

Another layer of complexity is the label switching issue. That is, the cluster IDs $\left\{ 1, \dots, H \right\}$ do not specify which cluster corresponds to which ID when all the cluster-specific prior for the normal distribution $p(\mu_{h},\sigma^{2}_{h})$ is the same. The solution is somehow make cluster IDs distinguishable. Ideally, this should be done on the substantive basis to set a different prior for each hypothesized latent cluster. In the one dimensional case we have, a common solution seems to constrain $\mu_{1} \le \mu_{2} \le \dots \le \mu_{H}$.

### Implementation
```{r}
normal_fixed_mixture_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture_unordered.stan")
biostan::print_stan_code(normal_fixed_mixture_stan_code, section = NULL)
```

### Fitting

#### 6 latent cluster model
Let us try a 6 latent cluster model with otherwise similar vague priors except Dirichlet(5,...,5) to avoid cluster degeneration.

```{r, results = 'hide'}
normal_fixed_mixture_stan_fit6 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 6*5,
                            H = 6,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
check_hmc_diagnostics(normal_fixed_mixture_stan_fit6)
print_relevant_pars(normal_fixed_mixture_stan_fit6)
traceplot_all(normal_fixed_mixture_stan_fit6)
pairs_plot_all(normal_fixed_mixture_stan_fit6)
plot_draws(normal_fixed_mixture_stan_fit6)
```

There were many divergent transitions (red dots in the pairs plots). The cross appearance of the mu pairs plot likely indicates that once the cluster has essentially zero probability, any value of mu is allowed. Interestingly, the resulting density estimates are quite similar.


#### 1 latent cluster model
Let us sanity check with just one cluster.

```{r, results = 'hide'}
normal_fixed_mixture_stan_fit1 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 1,
                            H = 1,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_stan_fit1)
traceplot_all(normal_fixed_mixture_stan_fit1)
plot_draws(normal_fixed_mixture_stan_fit1)
```

This gave a similar result to the first single normal fit, except that the additional $\pi$ parameter, which can only be 1 in this case.

#### 2 latent cluster model
This model has two latent clusters.

```{r, results = 'hide'}
normal_fixed_mixture_stan_fit2 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 2*5,
                            H = 2,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_stan_fit2)
traceplot_all(normal_fixed_mixture_stan_fit2)
pairs_plot_all(normal_fixed_mixture_stan_fit2)
plot_draws(normal_fixed_mixture_stan_fit2)
```

No divergent transitions were observed with just two clusters. However, Rhat statistics are high and mixing is poor including lp__.


#### 3 latent cluster model
```{r, results = 'hide'}
normal_fixed_mixture_stan_fit3 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 3*5,
                            H = 3,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_stan_fit3)
traceplot_all(normal_fixed_mixture_stan_fit3)
pairs_plot_all(normal_fixed_mixture_stan_fit3)
plot_draws(normal_fixed_mixture_stan_fit3)
```

Interestingly, lp__ has Rhat 1.00. However, the actual density estimates took on two shapes. One is with two separate peaks and the other is two peaks joined together.

#### 4 latent cluster model
```{r, results = 'hide'}
normal_fixed_mixture_stan_fit4 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 4*5,
                            H = 4,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_stan_fit4)
traceplot_all(normal_fixed_mixture_stan_fit4)
pairs_plot_all(normal_fixed_mixture_stan_fit4)
plot_draws(normal_fixed_mixture_stan_fit4)
```
```{r, eval = FALSE}
shinystan::launch_shinystan(normal_fixed_mixture_stan_fit4)
```


#### 5 latent cluster model
```{r, results = 'hide'}
normal_fixed_mixture_stan_fit5 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 5*5,
                            H = 5,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_stan_fit5)
traceplot_all(normal_fixed_mixture_stan_fit5)
pairs_plot_all(normal_fixed_mixture_stan_fit5)
plot_draws(normal_fixed_mixture_stan_fit5)
```

Rhat for lp__ increased. The resulting density estimates appear somewhat different.


#### 4 latent cluster model with ordered prior on mu
```{r}
normal_fixed_mixture_ordered_mu_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture.stan")
biostan::print_stan_code(normal_fixed_mixture_ordered_mu_stan_code, section = NULL)
```
```{r, results = 'hide'}
normal_fixed_mixture_ordered_mu_stan_fit4 <-
    rstan::stan(model_code = normal_fixed_mixture_ordered_mu_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 4*5,
                            H = 4,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_ordered_mu_stan_fit4)
traceplot_all(normal_fixed_mixture_ordered_mu_stan_fit4)
pairs_plot_all(normal_fixed_mixture_ordered_mu_stan_fit4)
plot_draws(normal_fixed_mixture_ordered_mu_stan_fit4)
```


#### 4 latent cluster model with ordered prior on Pi
```{r}
normal_fixed_mixture_ordered_Pi_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture_ordered_Pi.stan")
biostan::print_stan_code(normal_fixed_mixture_ordered_Pi_stan_code, section = NULL)
```
```{r, results = 'hide'}
normal_fixed_mixture_ordered_Pi_stan_fit4 <-
    rstan::stan(model_code = normal_fixed_mixture_ordered_Pi_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 4*5,
                            H = 4,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
print_relevant_pars(normal_fixed_mixture_ordered_Pi_stan_fit4)
traceplot_all(normal_fixed_mixture_ordered_Pi_stan_fit4)
pairs_plot_all(normal_fixed_mixture_ordered_Pi_stan_fit4)
plot_draws(normal_fixed_mixture_ordered_Pi_stan_fit4)
```

#### 4 latent cluster model with half-Cauchy prior on sigma
```{r}
normal_fixed_mixture_half_cauchy_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture_half_cauchy.stan")
biostan::print_stan_code(normal_fixed_mixture_half_cauchy_stan_code, section = NULL)
```
```{r, results = 'hide'}
normal_fixed_mixture_half_cauchy_stan_fit4 <-
    rstan::stan(model_code = normal_fixed_mixture_half_cauchy_stan_code,
                data = list(location = 0, scale = 2,
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$k_speed,
                            dirichlet_alpha = 4*5,
                            H = 4,
                            grid_max = grid_max, grid_min = grid_min, grid_length = grid_length),
                chains = 12)
```
```{r}
check_hmc_diagnostics(normal_fixed_mixture_half_cauchy_stan_fit4)
print_relevant_pars(normal_fixed_mixture_half_cauchy_stan_fit4,
                    pars = c("mu","Pi","sigma","lp__"))
traceplot_all(normal_fixed_mixture_half_cauchy_stan_fit4,
              pars = c("mu","Pi","sigma","lp__"))
pairs_plot_all(normal_fixed_mixture_half_cauchy_stan_fit4,
               pars = c("mu","Pi","sigma","lp__"))
plot_draws(normal_fixed_mixture_half_cauchy_stan_fit4)
```



<!-- ## Dirichlet Process Mixture of Normals -->
<!-- ### Model -->

<!-- ## Mixture of Polya Trees using Normal -->
<!-- ### Model -->

--------------------
- Top Page: http://rpubs.com/kaz_yos/
- Github: https://github.com/kaz-yos

```{r}
print(sessionInfo())
## Record execution time and multicore use
end_time <- Sys.time()
diff_time <- difftime(end_time, start_time, units = "auto")
cat("Started  ", as.character(start_time), "\n",
    "Finished ", as.character(end_time), "\n",
    "Time difference of ", diff_time, " ", attr(diff_time, "units"), "\n",
    "Used ", foreach::getDoParWorkers(), " cores\n",
    "Used ", foreach::getDoParName(), " as backend\n",
    sep = "")
```
