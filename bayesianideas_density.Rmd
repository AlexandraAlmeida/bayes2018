---
title: "BIDA: Density Estimation"
author: "Kazuki Yoshida"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r, message = FALSE, tidy = FALSE, echo = F}
## knitr configuration: http://yihui.name/knitr/options#chunk_options
library(knitr)
showMessage <- FALSE
showWarning <- TRUE
set_alias(w = "fig.width", h = "fig.height", res = "results")
opts_chunk$set(comment = "##", error= TRUE, warning = showWarning, message = showMessage,
               tidy = FALSE, cache = F, echo = T,
               fig.width = 7, fig.height = 7, dev.args = list(family = "sans"))
## for rgl
## knit_hooks$set(rgl = hook_rgl, webgl = hook_webgl)
## for animation
opts_knit$set(animation.fun = hook_ffmpeg_html)
## R configuration
options(width = 116, scipen = 5)
## Record start time
start_time <- Sys.time()
## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend for foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
```

## References
- Books
  - [(BIDA) Bayesian Ideas and Data Analysis An Introduction for Scientists and Statisticians](http://blogs.oregonstate.edu/bida/)
  - [(BDA) Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)
- Web sites
  - [Bayesian Statistics Using Stan 10 Finite Mixtures](http://www.stat.columbia.edu/~gelman/bda.course/_book/mixture-modeling-chapter.html)
  - [Finite mixture models in Stan](http://modernstatisticalworkflow.blogspot.com/2016/10/finite-mixture-models-in-stan.html)
  - [Identifying Bayesian Mixture Models](http://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html)
  - [Mixture models in Stan: you can use log_mix](https://andrewgelman.com/2017/08/21/mixture-models-stan-can-use-log_mix/)
- Software
  - [Stan Modeling Language User's Guide and Reference Manual, Version 2.17.0](http://mc-stan.org/users/documentation/)
  - [CRAN DPpackage: Bayesian Nonparametric Modeling in R](https://cran.r-project.org/package=DPpackage)
  - [J Stat Softw. 2011. DPpackage: Bayesian Non- and Semi-parametric Modelling in R.](https://www.jstatsoft.org/article/view/v040i05)


## Background
Here we have 82 data points in the galaxy from a 1-dimensional unknown distribution.

## Load packages

```{r}
library(tidyverse)
library(rstan)
## devtools::install_github('jburos/biostan', build_vignettes = TRUE, dependencies = TRUE)
## library(biostan)
library(DPpackage)
set.seed(732565397)
```

## Prepare data
```{r}
data(galaxy, package = "DPpackage")
galaxy <- galaxy %>%
    as_data_frame() %>%
    mutate(log_speed = log(speed))
galaxy
ggplot(data = galaxy, mapping = aes(x = log_speed)) +
    geom_point(y = 0.5) +
    scale_y_continuous(limits = c(0,1), breaks = NULL) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
```

The log speed data seem to show some distinct clusters.


## Single Normal
We will start with density estimation with a single normal distribution as a starting point.

### Model
$$\begin{align*}
  y_{i} | (\mu, \sigma^{2}) &\sim N(\mu, \sigma^{2})\\
  \\
  p(\mu,\sigma^{2}) &= p(\mu|\sigma^{2})p(\sigma^{2})\\
  &= N(\mu | m, s^{2}) Inverse-Gamma(\sigma^{2} | \alpha, \beta)\\
  &= \left[ \frac{1}{\sqrt{2\pi s^{2}}} \exp \left( - \frac{(\mu - m)^{2}}{2 \times s^{2}} \right) \right]
    \left[ \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^{2})^{-\alpha - 1} \exp \left( - \frac{\beta}{\sigma^{2}} \right) \right]\\
  &\text{where}\\
  m &= 0\\
  s^{2} &= 10^{3}\\
  \alpha &= 10^{-3}\\
  \beta &= 10^{-3}\\
  \end{align*}
$$

### Implementation
```{r}
normal_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal.stan")
biostan::print_stan_code(normal_stan_code, section = NULL)
```

### Fitting
```{r, cache = TRUE, results = 'hide'}
normal_stan_fit <-
    rstan::stan(model_code = normal_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed))
```

```{r}
normal_stan_fit
```

The sampling process seems ok.

```{r}
normal_stan_draws <- tidybayes::tidy_draws(normal_stan_fit)
## Evaluation grid
eval_grid <- seq(from = floor(min(galaxy$log_speed)), to = ceiling(max(galaxy$log_speed)), length.out = 10^2)
eval_df <- data_frame(x = eval_grid)
## Evaluate each density function over a grid
normal_stan_draws <- normal_stan_draws %>%
    ## Density function at each parameter draw
    mutate(density_fun = pmap(list(mu, sigma),
                              .f = function(mu, sigma) {
                                  partial(dnorm, mean = mu, sd = sigma)
                              }),
           data = list(eval_df)) %>%
    ## Grid evaluation
    mutate(data = pmap(list(density_fun, data),
                       .f = function(density_fun, data) {
                           data %>%
                               mutate(density = density_fun(x = x))
                       })) %>%
    select(.chain, .iteration, .draw, density_fun, data)
```

Plot density function draws.

```{r}
normal_stan_draws_unnest <- normal_stan_draws %>%
    select(-density_fun) %>%
    unnest()
normal_stan_draws_unnest_mean <-
    normal_stan_draws_unnest %>%
    group_by(x) %>%
    summarise(density = mean(density))
normal_stan_draws_unnest %>%
    ggplot(mapping = aes(x = x, y = density, group = interaction(.chain, .iteration, .draw))) +
    geom_line(size = 0.1, alpha = 1/20) +
    geom_line(data = normal_stan_draws_unnest_mean,
              color = "red", alpha = 0.5, size = 2,
              mapping = aes(group = NULL)) +
    geom_point(data = galaxy,
               mapping = aes(x = log_speed, group = NULL),
               y = 0) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
```

Apparently, a single normal distribution model is not a sufficient description of the density.


## Finite Mixture of Normals

Now we examine if modeling the distribution as a mixture of several underlying cluster-specific normals better fit the data. Here we assume some fixed number of clusters $H$.

### Model
Let $z_{i} \in \left\{ 1, \dots, H \right\}$ be the cluster membership latent variable and $\mathbf{z}_{i} = (I(z_{i}=1),\dots,I(z_{i}=H))^{T}$ be the vector indicator version. We have the following model.

$$\begin{align*}
  y_{i} | (z_{i}, \mu_{1},\dots,\mu_{H}, \sigma^{2}_{1},\dots,\sigma^{2}_{H}) &\sim N(\mu_{z_{i}}, \sigma^{2}_{z_{i}})\\
  \mathbf{z}_{i} | \boldsymbol{\pi} &\sim Multinomial(1, \boldsymbol{\pi})\\
  \\
  p(\mu_{h},\sigma^{2}_{h}) &= p(\mu_{h}|\sigma^{2}_{h})p(\sigma^{2}_{h})\\
  &= N(\mu_{h} | m, s^{2}) Inverse-Gamma(\sigma^{2}_{h} | \alpha, \beta)\\
  &= \left[ \frac{1}{\sqrt{2\pi s^{2}}} \exp \left( - \frac{(\mu_{h} - m)^{2}}{2 \times s^{2}} \right) \right]
    \left[ \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^{2}_{h})^{-\alpha - 1} \exp \left( - \frac{\beta}{\sigma^{2}_{h}} \right) \right]\\
  &\text{where}\\
  m &= 0\\
  s^{2} &= 10^{3}\\
  \alpha &= 10^{-3}\\
  \beta &= 10^{-3}\\
  \\
  p(\boldsymbol{\pi}) &\sim Dirichlet \left( \frac{\alpha}{H}, \dots, \frac{\alpha}{H} \right)\\
  \end{align*}
$$

Summing out the latent categorical variable $z_{i}$ results in the following (conditioning on parameters suppressed for simplicity) marginal density. Note the cluster membership latent variable $z_i$ is not measured, thus, it is a discrete parameter. Stan's Hamiltonian Monte Carlo (HMC) cannot deal with discrete parameters, this marginalization step is required fro Stan. JAGS seems to allow a discrete parameter and accepts the original model above.

$$\begin{align*}
  p(y) &= \sum^{H}_{z=1} p(y|z) p(z)\\
  &= \sum^{H}_{z=1} \pi_{z} p(y|z)\\
  &= \sum^{H}_{h=1} \pi_h N(y | \mu_{h}, \sigma^{2}_{h})\\
  \end{align*}
$$

Another layer of complexity is the label switching issue. That is, the cluster IDs $\left\{ 1, \dots, H \right\}$ do not specify which cluster corresponds to which ID when all the cluster-specific prior for the normal distribution $p(\mu_{h},\sigma^{2}_{h})$ is the same. The solution is somehow make cluster IDs distinguishable. Ideally, this should be done on the substantive basis to set a different prior for each hypothesized latent cluster. In the one dimensional case we have, a common solution seems to constrain $\mu_{1} \le \mu_{2} \le \dots \le \mu_{H}$.

### Implementation
```{r}
normal_fixed_mixture_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture.stan")
biostan::print_stan_code(normal_fixed_mixture_stan_code, section = NULL)
```
Please note the ordering constrain on the $\mu_{h}$.

### Fitting
#### 6 latent cluster model
Let us try a 6 latent cluster model with otherwise similar vague priors.

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit6 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 1,
                            H = 6))
```
```{r}
normal_fixed_mixture_stan_fit6
traceplot_all <- function(fit, H) {
    print(traceplot(fit, pars = sprintf("mu[%s]", seq_len(H))))
    print(traceplot(fit, pars = sprintf("sigma[%s]", seq_len(H))))
    print(traceplot(fit, pars = sprintf("Pi[%s]", seq_len(H))))
}
traceplot_all(normal_fixed_mixture_stan_fit6, 6)
```

This model broke down badly.

#### 1 latent cluster model
Let us sanity check with just one cluster.

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit1 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 1,
                            H = 1))
```
```{r}
normal_fixed_mixture_stan_fit1
traceplot_all(normal_fixed_mixture_stan_fit1, 1)
```

This gave a similar result to the first single normal fit, except that the additional $\pi$ parameter, which can only be 1 in this case.

#### 2 latent cluster model
This model has two latent clusters.

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit2 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 1,
                            H = 2))
```
```{r}
normal_fixed_mixture_stan_fit2
traceplot_all(normal_fixed_mixture_stan_fit2, 2)
```

This model also exhibits poor mixing. Particularly, $\sigma^{2}_{1}$ has a extremely broad posterior distribution.

#### 3 latent cluster model

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit3 <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 1,
                            H = 3))
```
```{r}
normal_fixed_mixture_stan_fit3
traceplot_all(normal_fixed_mixture_stan_fit3, 3)
```

Adding another latent cluster does not help.

#### 2 latent cluster model with increased Dirichlet alpha

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit2a <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 2,
                            H = 2))
```
```{r}
normal_fixed_mixture_stan_fit2a
traceplot_all(normal_fixed_mixture_stan_fit2a, 2)
```

Increasing the mass parameter for the Dirichlet prior on the cluster probabilities does not seem to help.

#### 2 latent cluster model with more precise prior on means

```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit2b <-
    rstan::stan(model_code = normal_fixed_mixture_stan_code,
                data = list(alpha = 10^(1), beta = 10^(1),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 1,
                            H = 2))
```
```{r}
normal_fixed_mixture_stan_fit2b
traceplot_all(normal_fixed_mixture_stan_fit2b, 2)
```

Making the priors on mean parameters more precise did not help.

#### 2 latent cluster model with tau (precision) ~ Gamma(a,b) parametrization
```{r}
normal_fixed_mixture_tau_stan_code <- biostan::read_stan_file("./bayesianideas_density_normal_fixed_mixture_tau.stan")
biostan::print_stan_code(normal_fixed_mixture_tau_stan_code, section = NULL)
```
```{r, cache = TRUE, results = 'hide'}
normal_fixed_mixture_stan_fit2c <-
    rstan::stan(model_code = normal_fixed_mixture_tau_stan_code,
                data = list(alpha = 10^(-3), beta = 10^(-3),
                            m = 0, s_squared = 10^(3),
                            n = nrow(galaxy),
                            y = galaxy$log_speed,
                            dirichlet_alpha = 2,
                            H = 2))
```
```{r}
normal_fixed_mixture_stan_fit2c
traceplot_all(normal_fixed_mixture_stan_fit2c, 2)
```




## Dirichlet Process Mixture of Normals
### Model

## Mixture of Polya Trees using Normal
### Model

--------------------
- Top Page: http://rpubs.com/kaz_yos/
- Github: https://github.com/kaz-yos

```{r}
print(sessionInfo())
## Record execution time and multicore use
end_time <- Sys.time()
diff_time <- difftime(end_time, start_time, units = "auto")
cat("Started  ", as.character(start_time), "\n",
    "Finished ", as.character(end_time), "\n",
    "Time difference of ", diff_time, " ", attr(diff_time, "units"), "\n",
    "Used ", foreach::getDoParWorkers(), " cores\n",
    "Used ", foreach::getDoParName(), " as backend\n",
    sep = "")
```
