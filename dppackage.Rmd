---
title: "DPpackage"
author: "Kazuki Yoshida"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r, message = FALSE, tidy = FALSE, echo = F}
## knitr configuration: http://yihui.name/knitr/options#chunk_options
library(knitr)
showMessage <- FALSE
showWarning <- TRUE
set_alias(w = "fig.width", h = "fig.height", res = "results")
opts_chunk$set(comment = "##", error= TRUE, warning = showWarning, message = showMessage,
               tidy = FALSE, cache = F, echo = T,
               fig.width = 7, fig.height = 7, dev.args = list(family = "sans"))
## for rgl
## knit_hooks$set(rgl = hook_rgl, webgl = hook_webgl)
## for animation
opts_knit$set(animation.fun = hook_ffmpeg_html)
## R configuration
options(width = 116, scipen = 5)
## Record start time
start_time <- Sys.time()
## Configure parallelization
## Parallel backend for foreach (also loads foreach and parallel; includes doMC)
library(doParallel)
## Reproducible parallelization
library(doRNG)
## Detect core count (Do not use on clusters)
n_cores <- parallel::detectCores()
## Used by parallel::mclapply() as default
options(mc.cores = n_cores)
## Used by doParallel as default
options(cores = n_cores)
## Register doParallel as the parallel backend for foreach
## http://stackoverflow.com/questions/28989855/the-difference-between-domc-and-doparallel-in-r
doParallel::registerDoParallel(cores = n_cores)
```

## References
- Books
  - [(BNPDA) Bayesian Nonparametric Data Analysis](https://www.springer.com/us/book/9783319189673)
- Software
  - [BNPDA code](https://web.ma.utexas.edu/users/pmueller/bnp/)
  - [CRAN DPpackage: Bayesian Nonparametric Modeling in R](https://cran.r-project.org/package=DPpackage)
  - [J Stat Softw. 2011. DPpackage: Bayesian Non- and Semi-parametric Modelling in R.](https://www.jstatsoft.org/article/view/v040i05)
- Papers
  - [Guindani (2014). A Bayesian Semi-parametric Approach for the Differential Analysis of Sequence Counts Data.](https://www.ncbi.nlm.nih.gov/pubmed/24833809)


## Load packages

```{r}
library(tidyverse)
library(DPpackage)
library(MCMCpack)
```

## Dirichlet Process
Here we will use the T cell receptor example in BNPDA (p10) for demonstration of Dirichlet process prior.

### Data
The data is based on Guindani 2014. Note count 0 does not exist in the data by design. Counts equal to and greater than 5 were not observed.

```{r}
tcell <- tribble(
    ~count, ~frequency,
    1, 37,
    2, 11,
    3, 5,
    4, 2,
    ## >= 5, 0,
    )
tcell
```

### Model
The model is the following.

$$
y_{i} | G \overset{iid}\sim G\\
G \sim DP(M, G_{0})
$$

The notation $y_{i} | G \overset{iid}\sim G$ puzzled me for a while, but the LHS data | parameter notation is necessary because we consider the joint distribution of data and parameter in Bayesian statistics. An iid argument like seen in Frequentist paradigm is only possible after fixing (conditioning on) the parameter. Importantly, once we marginalize this conditioning over the prior distribution, exchangeability remains, but not generally iid.

In the Dirichlet process formulation, each random probability measure $G$ retains the same support as the centering measure $G_{0}$. Here we will choose a Poisson with mean 2 that truncates at 1 (zeros are removed). Because we have a discrete centering measure, the partitioning property is relatively clear. If we collapse all values beyond 8 to 8+ bin, the following is the distribution.

$$
\begin{bmatrix}
   G(0)\\
   G(1)\\
   \vdots\\
   G(8+)\\
 \end{bmatrix}
\sim Dirichlet
\begin{bmatrix}
   M G_{0}(0)\\
   M G_{0}(1)\\
   \vdots\\
   M G_{0}(8+)\\
 \end{bmatrix}
$$


### Prior

Now we define a function to give appropriately collapsed finite probability vector for the centering measure.

```{r}
G0_vector <- function(lambda, min, max) {
    ## values below min are truncated
    ## values above max are collapsed

    ## Probabilities from Poisson(lambda) for min:max
    p_vec <- dpois(x = min:max, lambda = lambda)
    ## Probability for max+1 ...
    p_upper_tail <- 1 - ppois(q = max, lambda = lambda)
    ## Collapse to max
    p_vec[length(p_vec)] <- p_vec[length(p_vec)] + p_upper_tail
    ## Renormalize
    p_vec <- p_vec / sum(p_vec)
    ## Name
    names(p_vec) <- min:max
    ##
    return(p_vec)
}

## Collapse all values beyond 8 to 8+ bin
G0_vector(lambda = 2, min = 1, max = 8)
```

Now we can define a function to create random Dirichlet draws given the probability vector and mass $M$.

```{r}
## This function gives random Dirichlet draws via normalization of Gammas.
MCMCpack::rdirichlet

## Make sure G0_vector has integer names
draw_dirichlet <- function(n, M, G0_vector) {
    MCMCpack::rdirichlet(n, alpha = M * G0_vector) %>%
    t %>%
    as_data_frame %>%
    mutate(y = names(G0_vector)) %>%
    gather(key = .iter, value = p, -y) %>%
    mutate(.iter = as.integer(gsub("V", "", .iter)))
}

draw_dirichlet(n = 10, M = 1, G0_vector = G0_vector(lambda = 2, min = 1, max = 8))
```

Let us visualize some random draws from the prior at different $M$.

```{r}
G0_vector_values <- G0_vector(lambda = 2, min = 1, max = 8)

prior_mean <- data_frame(y = names(G0_vector_values),
                         p = G0_vector_values,
                         .iter = 0)

prior_draws <- bind_rows(
    draw_dirichlet(n = 10, M = 0.1, G0_vector = G0_vector_values) %>%
    mutate(M = 0.1),
    draw_dirichlet(n = 10, M = 1, G0_vector = G0_vector_values) %>%
    mutate(M = 1),
    draw_dirichlet(n = 10, M = 10, G0_vector = G0_vector_values) %>%
    mutate(M = 10),
    draw_dirichlet(n = 10, M = 100, G0_vector = G0_vector_values) %>%
    mutate(M = 100),
)

prior_draws %>%
    ggplot(mapping = aes(x = y, y = p, group = .iter)) +
    geom_line() +
    geom_line(data = prior_mean, size = 2) +
    facet_wrap(~ M) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())

```

### Fitting

```{r}

## data
## healthy Tconv mouse 2
yf <- c(37,11,5,2) # frequencies
xf <- c(1,2,3,4)   # counts
## y <- rep(xf,yf)    # raw data
## n <- length(y)
## k <- n             # initialize

## hyperparameters
## a0 <- 1;   b0 <- 1   # hyperprior b ~ Ga(a0,b0)
## a <- 1; b <- .05     # G0(mu) = Ga(a,b)
## lambda <- 300        # k ~ Poi(lambda)
## M <- 1
## H <- 10
## N <- 25; p=8

rdiric<- function(n,a) {
    ## generates x ~ Dir(a,...a) (n-dim)
    p <- length(a)
    m <- matrix(nrow=n,ncol=p)
    for (i in 1:p) {
        m[,i] <- rgamma(n,a[i])
    }
    sumvec <- m %*% rep(1,p)
    m / as.vector(sumvec)
}

sample.dponly <- function(N=10,M=1,p=8) {
    ## generates posterior p(G | y)
    ## for yi ~ G
    ## G0:   prior mean
    ## Ghat: empirical
    ## Gbar: posterior mean
    ## G:    posterior sample
    xgrid <- 1:p
    r <-  1/(1-dpois(0, lambda=2)) # trunction to x>=1
    G0 <- dpois(xgrid, lambda=2) * r # prior base measure
    G1 <- M*G0                    # post base measure
    G1[xf] <- G1[xf]+yf     # +1 because xgrid starts at 0
    ## Sample a random probability measure N times
    G <- rdiric(N,G1)
    Gcdf <- apply(G,1,cumsum)
    n <- sum(yf)
    Gbar <- G1/(n+M)
    Gbarcdf <- cumsum(Gbar)

    G0cdf <- cumsum(G0)

    Ghat <- rep(0,p) # initialize
    n <- sum(yf)
    Ghat[xf] <- yf/n
    Ghatcdf <- cumsum(Ghat)
    ##
    return(Ghatcdf)
  }
```

```{r}
sample.dponly()
```

## Dirichlet Process Mixture


--------------------
- Top Page: http://rpubs.com/kaz_yos/
- Github: https://github.com/kaz-yos

```{r}
print(sessionInfo())
## Record execution time and multicore use
end_time <- Sys.time()
diff_time <- difftime(end_time, start_time, units = "auto")
cat("Started  ", as.character(start_time), "\n",
    "Finished ", as.character(end_time), "\n",
    "Time difference of ", diff_time, " ", attr(diff_time, "units"), "\n",
    "Used ", foreach::getDoParWorkers(), " cores\n",
    "Used ", foreach::getDoParName(), " as backend\n",
    sep = "")
```
